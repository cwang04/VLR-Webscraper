{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5136952",
   "metadata": {},
   "outputs": [],
   "source": [
    "!py -m venv venv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4058e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!py -m pip install requests\n",
    "!py -m pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16248f4d",
   "metadata": {},
   "source": [
    "Creates a method to webscrape tournament stat pages for vlr. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b8680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports necessary libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4521ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to be applied for every vlr tournament, takes the url of the webpage and the name of the file that you want to save it as\n",
    "def vlr_tournament_webscrape(URL, csv_filename):\n",
    "    '''Function to scrape through the stats page of a valorant tournament on vlr.gg.\n",
    "    Uses beautifulsoup to scrape through the html data and extract relevant information.\n",
    "    example code to run to collect VCT Champs 2022 stats:\n",
    "    vlr_tournament_webscrape('https://www.vlr.gg/event/stats/1015/valorant-champions-2022', 'vctchamps22')'''\n",
    "    page = requests.get(URL)\n",
    "\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    tbody = soup.find('table').find('tbody').find_all('tr')\n",
    "\n",
    "    #parsing the web scraped data\n",
    "    df = pd.DataFrame(columns=['Player', 'Country', 'Team', 'Agent_1', 'Agent_2', 'Agent_3', 'Agent_4', 'Agent_5', 'Rounds', \n",
    "                                     'ACS', 'KD', 'KAST', 'ADR', 'KPR', 'APR', 'FKPR', 'FDPR', 'HS_Rate', 'Clutch_Rate', 'Succesful_Clutches', \n",
    "                                     'Clutches_Attempted', 'Max_Kills', 'Kills', 'Deaths', 'Assists', 'FK', 'FD'])\n",
    "\n",
    "    for tr in tbody:\n",
    "        l = []\n",
    "        #gets the player name\n",
    "        player = tr.find('div', class_='text-of').text\n",
    "        l.append(player)\n",
    "        #gets the country abbreviation from flag img href\n",
    "        country = tr.find('i')['class'][1].split('-')[1]\n",
    "        l.append(country)\n",
    "        #gets the team name from text\n",
    "        team = tr.find('div', class_='stats-player-country').text\n",
    "        l.append(team)\n",
    "        #get the agents played\n",
    "        agentlist = tr.find('td', class_='mod-agents').find('div').find_all('img')\n",
    "        agents=[]\n",
    "        for i in range(5):\n",
    "            if i < len(agentlist):\n",
    "                agents.append(agentlist[i]['src'].split('/')[-1][:-4])\n",
    "            else:\n",
    "                agents.append('None')\n",
    "        l+=agents\n",
    "        #get number of rounds played\n",
    "        rounds = tr.find('td', class_='mod-rnd').text\n",
    "        l.append(int(rounds))\n",
    "        #get the next few stats (acs to clutch%)\n",
    "        stats_acs_clutch = tr.find_all('td', class_='mod-color-sq')\n",
    "        statlist = []\n",
    "        for stat in stats_acs_clutch:\n",
    "            temp = stat.find('div').find('span').text\n",
    "            if temp=='':\n",
    "                statlist.append(0)\n",
    "            elif '%' in temp:\n",
    "                statlist.append(float(temp.replace('%',''))/100)\n",
    "            else:\n",
    "                statlist.append(float(temp))\n",
    "        l+=statlist\n",
    "        #get the succesful clutches and the attempted clutches\n",
    "        clutches = tr.find('td', class_='mod-cl').text.strip()\n",
    "        if clutches!='':\n",
    "            l.append(int(clutches.split('/')[0]))\n",
    "            l.append(int(clutches.split('/')[1]))\n",
    "        else:\n",
    "            l.append(0)\n",
    "            l.append(0)\n",
    "        #get the max kills in a map\n",
    "        max_kills = tr.find('td', class_='mod-a mod-kmax').text.strip()\n",
    "        l.append(int(max_kills))\n",
    "        #get the rest of the stats kills - FD\n",
    "        raw_stats = tr.find_all('td')[:][-5:]\n",
    "        for stat in raw_stats:\n",
    "            l.append(int(stat.text))\n",
    "        df.loc[len(df.index)] = l  \n",
    "    \n",
    "    print(df)\n",
    "    df.to_csv(csv_filename+'.csv', header=True, index=False)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fcec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleans up the data, i.e. replaces the two letter country code with the full country name\n",
    "def clean_vlr_data(csv_filename, new_csv_filename):\n",
    "    '''A method that will clean up the webscraped vlr tournament data.\n",
    "    The main point of this method is to convert the two letter country codes to\n",
    "    their corresponding countries, as the codes are not always intuitive.\n",
    "    Example code for how to run:\n",
    "    clean_vlr_data('vctchamps22', 'vctchamps22')\n",
    "    '''\n",
    "    #dictionary of country codes to the country names, more to be added later\n",
    "    country = {'cl':'Chile', 'us':'United States', 'fi':'Finland', 'cn':'China', 'ca':'Canada', 'jp':'Japan', 'tr':'Turkey',\n",
    "              'sg':'Singapore', 'lv':'Latvia', 'kr':'Korea', 'se':'Sweden', 'br':'Brazil', 'be':'Belgium', 'id':'Indonesia',\n",
    "              'un':'Not Representing', 'ru':'Russia', 'th':'Thailand', 'gb':'United Kingdom', 'ar':'Argentina', 'ua':'Ukraine',\n",
    "              'kz':'Kazhakstan', 'my':'Malaysia', 'fr':'France', 'cz':'Czech Republic', 'hr':'Croatia', 'lt':'Lithuania', 'pl':'Poland',\n",
    "              'es':'Estonia', 'dk':'Denmark', 'ph':'Philipines'}\n",
    "    df = pd.read_csv(csv_filename+'.csv')\n",
    "    #converts the country codes to its corresponding country\n",
    "    df['Country'] = df['Country'].apply(lambda x: country[x])\n",
    "    \n",
    "    print(df)\n",
    "    df.to_csv(new_csv_filename+'.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ba52a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vlr_tournament_webscrape('https://www.vlr.gg/event/stats/1162/game-changers-brazil-series-2', 'gamechangers_brazil_22')\n",
    "clean_vlr_data('gamechangers_brazil_22' ,'gamechangers_brazil_22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e56fb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deactivate python env\n",
    "!conda deactivate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1028c16e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
